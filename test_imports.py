#!/usr/bin/env python3
"""
Test script to verify all imports work and URL extraction is functional.
"""


def test_imports():
    """Test all required imports."""
    print("ğŸ” Testing Imports...")

    try:
        import playwright.async_api

        print("âœ… playwright.async_api imported successfully")
    except ImportError as e:
        print(f"âŒ playwright.async_api import failed: {e}")
        return False

    try:
        import pandas

        print("âœ… pandas imported successfully")
    except ImportError as e:
        print(f"âŒ pandas import failed: {e}")
        return False

    try:
        import numpy

        print("âœ… numpy imported successfully")
    except ImportError as e:
        print(f"âŒ numpy import failed: {e}")
        return False

    try:
        from adapters.torob_search import TorobScraper

        print("âœ… TorobScraper imported successfully")
    except ImportError as e:
        print(f"âŒ TorobScraper import failed: {e}")
        return False

    try:
        from core.exporter_excel import ExcelExporter

        print("âœ… ExcelExporter imported successfully")
    except ImportError as e:
        print(f"âŒ ExcelExporter import failed: {e}")
        return False

    print("\nğŸ‰ All imports successful!")
    return True


def test_url_extraction():
    """Test URL extraction functionality."""
    print("\nğŸ” Testing URL Extraction...")

    try:
        import asyncio
        from adapters.torob_search import TorobScraper

        async def test_scraper():
            async with TorobScraper(headless=True) as scraper:
                # Test search
                results = await scraper.search_parts(
                    "Ú†Ø±Ø§Øº Ø³Ù…Øª Ø±Ø§Ø³Øª ØªÛŒÚ¯Ùˆ Û¸ Ù¾Ø±Ùˆ", max_scroll_attempts=1
                )

                print(f"ğŸ“Š Found {len(results)} products")

                if results:
                    print("\nğŸ“‹ Sample results:")
                    for i, result in enumerate(results[:3]):  # Show first 3
                        print(
                            f"   {i+1}. Title: {result.get('title_raw', 'N/A')[:50]}..."
                        )
                        print(f"      URL: {result.get('product_url', 'N/A')}")
                        print(f"      Price: {result.get('price_raw', 'N/A')}")
                        print(f"      Seller: {result.get('seller_name', 'N/A')}")
                        print()

                return len(results) > 0

        result = asyncio.run(test_scraper())
        if result:
            print("âœ… URL extraction working!")
        else:
            print("âŒ No products found")
        return result

    except Exception as e:
        print(f"âŒ URL extraction test failed: {e}")
        return False


if __name__ == "__main__":
    print("ğŸš€ Testing Torob Scraper Environment")
    print("=" * 50)

    # Test imports
    imports_ok = test_imports()

    if imports_ok:
        # Test URL extraction
        url_ok = test_url_extraction()

        if url_ok:
            print("\nğŸ‰ All tests passed! The scraper is ready to use.")
        else:
            print("\nâš ï¸  Imports work but URL extraction needs attention.")
    else:
        print("\nâŒ Import issues need to be resolved first.")

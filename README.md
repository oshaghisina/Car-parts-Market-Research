# ğŸš— Torob Scraper

[![CI/CD Pipeline](https://github.com/oshaghisina/Car-parts-Market-Research/workflows/CI/CD%20Pipeline/badge.svg)](https://github.com/oshaghisina/Car-parts-Market-Research/actions)
[![Python Version](https://img.shields.io/badge/python-3.8%2B-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Docker](https://img.shields.io/badge/docker-%230db7ed.svg?style=flat&logo=docker&logoColor=white)](https://www.docker.com/)
[![Flask](https://img.shields.io/badge/flask-%23000.svg?style=flat&logo=flask&logoColor=white)](https://flask.palletsprojects.com/)

**Advanced Automotive Parts Price Scraper with Modern Web Interface**

A powerful, production-ready web scraper for extracting automotive parts prices from Torob.com with advanced features including caching, parallel processing, real-time progress tracking, and a beautiful web interface.

<!-- CI/CD Test: Triggering workflow for testing -->

## âœ¨ Features

### ğŸ” **Advanced Scraping**
- **Two-Stage Scraping**: Search page + Product page drill-down
- **Smart Filtering**: Relevance scoring and negative category filtering
- **JSON Extraction**: Robust data extraction from dynamic content
- **Rate Limiting**: Respectful scraping with configurable delays

### âš¡ **High Performance**
- **Parallel Processing**: Multi-threaded scraping for speed
- **Intelligent Caching**: File-based caching with TTL
- **Memory Optimization**: Efficient memory usage
- **Progress Tracking**: Real-time progress indicators

### ğŸŒ **Modern Web Interface**
- **Responsive Design**: Works on desktop, tablet, and mobile
- **Live Log Viewer**: Real-time terminal-style logging
- **File Upload**: CSV file support for batch processing
- **Results Download**: Direct Excel file download
- **Task Management**: View and manage scraping tasks

### ğŸ“Š **Rich Analytics**
- **Comprehensive Reports**: Multi-sheet Excel exports
- **Price Analysis**: Min/max/median/mean calculations
- **Seller Statistics**: Unique seller analysis
- **Conditional Formatting**: Visual outlier detection

### ğŸ› ï¸ **Developer Friendly**
- **CLI Interface**: Command-line tool for developers
- **RESTful API**: Clean API endpoints
- **Docker Support**: Containerized deployment
- **CI/CD Pipeline**: Automated testing and deployment

## ğŸš€ Quick Start

### **Option 1: Docker (Recommended)**

```bash
# Clone the repository
git clone https://github.com/oshaghisina/Car-parts-Market-Research.git
cd torob-scraper

# Run with Docker Compose
docker-compose up -d

# Access the web interface
open http://localhost:5001
```

### **Option 2: Local Installation**

```bash
# Clone the repository
git clone https://github.com/oshaghisina/Car-parts-Market-Research.git
cd torob-scraper

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Install Playwright browsers
playwright install

# Start the web interface
python web_app.py

# Or use the CLI
python main_torob_cli.py
```

## ğŸ“– Usage

### **Web Interface**

1. **Open your browser** and go to `http://localhost:5001`
2. **Enter part information**:
   - Part name (required)
   - Part code (optional)
   - Keywords (auto-generated if empty)
3. **Start scraping** and watch real-time progress
4. **Download results** as Excel file

### **Command Line Interface**

```bash
# Interactive mode
python main_torob_cli.py

# Help
python main_torob_cli.py --help
```

### **API Usage**

```python
from core.pipeline_torob import TorobTwoStagePipeline

# Create pipeline
parts_data = [{
    'part_id': 'test_001',
    'part_name': 'Ú†Ø±Ø§Øº Ø³Ù…Øª Ø±Ø§Ø³Øª ØªÛŒÚ¯Ùˆ Û¸ Ù¾Ø±Ùˆ',
    'part_code': 'TIGGO8-HEADLIGHT-RH',
    'keywords': 'Ú†Ø±Ø§Øº Ø³Ù…Øª Ø±Ø§Ø³Øª ØªÛŒÚ¯Ùˆ Û¸ Ù¾Ø±Ùˆ automotive part'
}]

pipeline = TorobTwoStagePipeline(parts_data, 'results.xlsx')

# Run scraping
import asyncio
asyncio.run(pipeline.run_pipeline())
```

## ğŸ—ï¸ Architecture

```
torob_scraper/
â”œâ”€â”€ ğŸŒ web_app.py              # Flask web application
â”œâ”€â”€ ğŸ–¥ï¸ main_torob_cli.py       # CLI interface
â”œâ”€â”€ ğŸ“ adapters/               # Web scraping adapters
â”‚   â””â”€â”€ torob_search.py        # Torob.com scraper
â”œâ”€â”€ ğŸ“ core/                   # Core business logic
â”‚   â”œâ”€â”€ pipeline_torob.py      # Main pipeline
â”‚   â”œâ”€â”€ entity_normalizer.py   # Data normalization
â”‚   â”œâ”€â”€ filtering.py           # Relevance filtering
â”‚   â”œâ”€â”€ dedupe.py             # Deduplication
â”‚   â”œâ”€â”€ exporter_excel.py     # Excel export
â”‚   â”œâ”€â”€ config_manager.py     # Configuration
â”‚   â”œâ”€â”€ cache_manager.py      # Caching system
â”‚   â”œâ”€â”€ parallel_processor.py # Parallel processing
â”‚   â”œâ”€â”€ progress_tracker.py   # Progress tracking
â”‚   â””â”€â”€ cli_enhancer.py       # CLI enhancements
â”œâ”€â”€ ğŸ“ utils/                  # Utility functions
â”‚   â””â”€â”€ text.py               # Text processing
â”œâ”€â”€ ğŸ“ templates/              # HTML templates
â”œâ”€â”€ ğŸ“ static/                 # CSS/JS assets
â”œâ”€â”€ ğŸ³ Dockerfile             # Docker configuration
â”œâ”€â”€ ğŸ³ docker-compose.yml     # Docker Compose
â””â”€â”€ âš™ï¸ config.yaml            # Configuration file
```

## âš™ï¸ Configuration

The scraper is highly configurable through `config.yaml`:

```yaml
# Scraping settings
scraping:
  base_url: "https://torob.com"
  delay_range:
    min: 1.5
    max: 3.0
  scroll:
    max_attempts: 10
    delay: 2.0

# Performance settings
performance:
  parallel:
    enabled: true
    max_workers: 3
    batch_size: 5

# Caching settings
caching:
  enabled: true
  ttl_hours: 24
  max_size_mb: 100

# Web interface settings
web:
  host: "0.0.0.0"
  port: 5001
  debug: false
```

## ğŸ§ª Testing

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=. --cov-report=html

# Run specific test categories
pytest -m unit
pytest -m integration
pytest -m "not slow"
```

## ğŸš€ Deployment

### **Docker Deployment**

```bash
# Build image
docker build -t torob-scraper .

# Run container
docker run -p 5001:5001 torob-scraper

# Or use Docker Compose
docker-compose up -d
```

### **Production Deployment**

```bash
# Install production dependencies
pip install -r requirements.txt

# Set environment variables
export FLASK_ENV=production
export PYTHONPATH=/path/to/torob-scraper

# Run with production server
gunicorn -w 4 -b 0.0.0.0:5001 web_app:app
```

### **Kubernetes Deployment**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: torob-scraper
spec:
  replicas: 3
  selector:
    matchLabels:
      app: torob-scraper
  template:
    metadata:
      labels:
        app: torob-scraper
    spec:
      containers:
      - name: torob-scraper
        image: yourusername/torob-scraper:latest
        ports:
        - containerPort: 5001
        env:
        - name: FLASK_ENV
          value: "production"
```

## ğŸ“Š Performance

### **Benchmarks**
- **Single Part**: ~2-3 minutes
- **Multiple Parts**: ~1-2 minutes per part (parallel)
- **Memory Usage**: ~100-200MB per task
- **Cache Hit Rate**: ~80% for repeated searches

### **Optimization Features**
- **Parallel Processing**: 3x faster for multiple parts
- **Intelligent Caching**: 80% faster for repeated searches
- **Memory Management**: Efficient resource usage
- **Progress Tracking**: Real-time user feedback

## ğŸ¤ Contributing

We welcome contributions! Please see our [Contributing Guidelines](CONTRIBUTING.md) for details.

### **Development Setup**

```bash
# Fork and clone the repository
git clone https://github.com/oshaghisina/Car-parts-Market-Research.git
cd torob-scraper

# Create development environment
python -m venv venv
source venv/bin/activate

# Install development dependencies
pip install -r requirements.txt
pip install -e ".[dev]"

# Install pre-commit hooks
pre-commit install

# Run tests
pytest
```

### **Code Style**

We use:
- **Black** for code formatting
- **isort** for import sorting
- **flake8** for linting
- **mypy** for type checking

```bash
# Format code
black .
isort .

# Lint code
flake8 .

# Type check
mypy .
```

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **Torob.com** for providing the automotive parts marketplace
- **Playwright** for excellent browser automation
- **Flask** for the web framework
- **Pandas** for data processing
- **OpenPyXL** for Excel export functionality

## ğŸ“ Support

- **Documentation**: [Wiki](https://github.com/oshaghisina/Car-parts-Market-Research/wiki)
- **Issues**: [GitHub Issues](https://github.com/oshaghisina/Car-parts-Market-Research/issues)
- **Discussions**: [GitHub Discussions](https://github.com/oshaghisina/Car-parts-Market-Research/discussions)
- **Email**: contact@torobscraper.com

## ğŸ—ºï¸ Roadmap

- [ ] **v1.1**: Multi-language support
- [ ] **v1.2**: Advanced analytics dashboard
- [ ] **v1.3**: Mobile app
- [ ] **v1.4**: API rate limiting
- [ ] **v1.5**: Machine learning price predictions

---

**â­ Star this repository if you find it useful!**

**ğŸ› Found a bug? Please report it in the [Issues](https://github.com/oshaghisina/Car-parts-Market-Research/issues) section.**

**ğŸ’¡ Have an idea? Start a [Discussion](https://github.com/oshaghisina/Car-parts-Market-Research/discussions)!**